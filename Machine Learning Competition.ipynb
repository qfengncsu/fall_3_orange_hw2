{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./MLProjectData.csv')\n",
    "test = pd.read_csv('./testData.csv')\n",
    "train['cat1'] = train.cat1.astype('category')\n",
    "train['cat2'] = train.cat2.astype('category')\n",
    "\n",
    "features = train.drop(axis = 1, columns= ['target'])\n",
    "labels = train['target']\n",
    "#One hot coding\n",
    "features_hot = pd.get_dummies(features, columns= ['cat1','cat2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix\n",
    "Try to analyze association among those boolean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols = [col for col in train.columns if 'cat' in col]\n",
    "tmp_df = np.full((24, 24), 10)\n",
    "tmp_df = pd.DataFrame(tmp_df)\n",
    "tmp_df.columns = cat_cols[2:]\n",
    "tmp_df.index = cat_cols[2:]\n",
    "\n",
    "for col1 in cat_cols[2:]:\n",
    "    for col2 in cat_cols[2:]:\n",
    "        tmp_df.loc[col1, col2] = jaccard_similarity_score(train[col1], train[col2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(list(tmp_df.values.flat));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualization exploration\n",
    "for i in train:\n",
    "    if train[i].dtype == 'float64':\n",
    "        plt.boxplot(train[i])\n",
    "        plt.title(i)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in train:\n",
    "    if train[j].dtype == 'bool':\n",
    "        (train[j].value_counts()/train.shape[0]).plot(kind = 'bar')\n",
    "        plt.title(j)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the noisy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from featexp import get_univariate_plots\n",
    "from featexp import get_trend_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train:\n",
    "    if train[i].dtype == 'float64':\n",
    "        get_univariate_plots(data=train, target_col='target', features_list=[i], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select the features with correlation large than 0.6\n",
    "stats = get_trend_stats(data = train1, target_col= 'target', data_test= test1)\n",
    "feature_list = stats[stats['Trend_correlation'] > 0.6]['Feature']\n",
    "feature_list = feature_list[feature_list.str.contains('num')]\n",
    "feature_list = feature_list.append(pd.Series(['cat1','cat2','cat3','cat4']))\n",
    "features = train.drop(axis = 1, columns= ['target'])[feature_list]\n",
    "labels = train['target']\n",
    "features_hot = pd.get_dummies(features, columns= ['cat1','cat2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size = 0.3, random_state = 123)\n",
    "train_hot_x, test_hot_x, train_hot_y, test_hot_y = train_test_split(features_hot, labels, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function help use calculate MAE\n",
    "def mae(x,y):\n",
    "    \"\"\"calculate the MAE(mean of absolute error)\"\"\"\n",
    "    mae = abs(x - y).mean()\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function help us do 5-fold cross-validation\n",
    "def get_folds_index(df=None, n_splits=5):\n",
    "    \"\"\"Returns dataframe indices corresponding to group\"\"\"\n",
    "    kf = KFold(n_splits=5, random_state= 234)\n",
    "    fold_ids = []\n",
    "    ids = df.index\n",
    "    for train_idx, test_idx in kf.split(X=df):\n",
    "        fold_ids.append([ids[train_idx], ids[test_idx]])\n",
    "    return fold_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds_hot = get_folds_index(features_hot)\n",
    "mae_vc_mean = []\n",
    "for train_idx_hot, test_idx_hot  in folds_hot:\n",
    "    \"\"\"get the train split as well as the test split according to the assignment of 5 validaiton\"\"\"\n",
    "    train_x_cv_hot, train_y_cv_hot = features_hot.iloc[train_idx_hot], labels.iloc[train_idx_hot]\n",
    "    test_x_cv_hot, test_y_cv_hot = features_hot.iloc[test_idx_hot], labels.iloc[test_idx_hot]\n",
    "    mae_vc_mean.append(mae(train_y_cv_hot.mean(),test_y_cv_hot))\n",
    "    \n",
    "print('The baseline MAE (mean of absolute error)  according to 5-fold validation is ', sum(mae_vc_mean)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds_hot = get_folds_index(features_hot)\n",
    "mae_vc_linear = []\n",
    "for train_idx_hot, test_idx_hot  in folds_hot:\n",
    "    \"\"\"get the train split as well as the test split according to the assignment of 5 validaiton\"\"\"\n",
    "    train_x_cv_hot, train_y_cv_hot = features_hot.iloc[train_idx_hot], labels.iloc[train_idx_hot]\n",
    "    test_x_cv_hot, test_y_cv_hot = features_hot.iloc[test_idx_hot], labels.iloc[test_idx_hot]\n",
    "    reg_vc = LinearRegression().fit(train_x_cv_hot, train_y_cv_hot)\n",
    "    mae_vc_linear.append(mae(reg_vc.predict(test_x_cv_hot),test_y_cv_hot))\n",
    "print('The  MAE (mean of absolute error) using linear regression according to 5-fold validation is ', sum(mae_vc_linear)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "alpha = 100\n",
    "clf = linear_model.Lasso(alpha=float(alpha) , normalize=True)\n",
    "lasso = mae(clf.predict(test_hot_x), test_hot_y)\n",
    "print('The MAE (mean of absolute error) using lasso is ', lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune the alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "clf_lasso_cv = LassoCV(cv = 5, random_state= 123, max_iter = 10000).fit(features_hot, labels)\n",
    "clf_lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the best alph is 30 \n",
    "alpha = 30\n",
    "clf = linear_model.Lasso(alpha=float(alpha) , normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mae_lasso_vc = []\n",
    "for train_idx_hot, test_idx_hot  in folds_hot:\n",
    "    \"\"\"get the train split as well as the test split according to the assignment of 5 validaiton\"\"\"\n",
    "    train_x_cv_hot, train_y_cv_hot = features_hot.iloc[train_idx_hot], labels.iloc[train_idx_hot]\n",
    "    test_x_cv_hot, test_y_cv_hot = features_hot.iloc[test_idx_hot], labels.iloc[test_idx_hot]\n",
    "    clf.fit(train_x_cv_hot, train_y_cv_hot)\n",
    "    mae_lasso_vc.append(mae(clf.predict(test_x_cv_hot),test_y_cv_hot))\n",
    "print('The MAE (mean of absolute error) using lasso according to 5 fold validation is ', sum(mae_lasso_vc)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Lasso with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "pca.fit(np.array(features_hot))\n",
    "transform_features3 = pd.DataFrame(pca.transform(np.array(features_hot)),columns=['x','y','z'])\n",
    "trans_train_x, trans_test_x, trans_train_y, trans_test_y = train_test_split(transform_features3, labels, test_size = 0.3, random_state = 123)\n",
    "clf.fit(trans_train_x, trans_train_y)\n",
    "mae(clf.predict(trans_test_x),trans_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 120, random_state = 42, criterion='mae',max_features=0.1, n_jobs = -1, min_samples_leaf=20)\n",
    "rf.fit(train_x, train_y)\n",
    "mae_random_forest = mae(rf2.predict(test_x),test_y)\n",
    "print('The random forest MAE (mean of absolute error)  without tuning the model is ', mae_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check the feature importance\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try grid search to tune the hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 15, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [20, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [20, 70]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 30, scoring='neg_mean_absolute_error', \n",
    "                              cv = 5, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(features_hot, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The MAE using optimal random forest according to 5 fold validation is ', -rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_xgmodel = xgb.XGBRegressor(objective ='reg:linear',learning_rate= 0.01, n_estimators = 1000, max_depth = 3, subsample = 0.8, colsample_bytree = 1, gamma = 1)\n",
    "start_xgmodel.fit(train_hot_x, train_hot_y)\n",
    "XG_mean = mae(start_xgmodel.predict(test_hot_x),test_hot_y)\n",
    "print('The MAE (mean of absolute error) using a begining xgboost is ', XG_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decide the optimized n_estimate\n",
    "eval_set = [(train_hot_x, train_hot_y), (test_hot_x, test_hot_y)]\n",
    "eval_metric = ['mae','error']\n",
    "%time start_xgmodel.fit(train_hot_x, train_hot_y, eval_metric=eval_metric, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the optimal n_estimate is 600\n",
    "# now we are trying to decide the depth of tree\n",
    "# we will use randomized search since it is more efficient and time saving\n",
    "\n",
    "xgb_start = xgb.XGBRegressor(learning_rate= 0.01, n_estimators= 600, objective ='reg:linear', nthread=4, silent=True )\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(3,6,4)]\n",
    "min_child_weight = [10,20,40]\n",
    "gamma = [0.5, 1, 1.5, 2, 5]\n",
    "subsample = [0.6, 0.8, 1.0]\n",
    "colsample_bytree = [0.6, 0.8, 1.0]\n",
    "\n",
    "params_first = {\n",
    "    'min_child_weight': min_child_weight,\n",
    "    'max_depth': max_depth,\n",
    "    'gamma': gamma,\n",
    "    'subsample': subsample,\n",
    "    'colsample_bytree':colsample_bytree\n",
    "               }\n",
    "pprint(params_first)\n",
    "\n",
    "gsearch = RandomizedSearchCV(xgb_start, param_distributions = params_first, scoring='neg_mean_absolute_error', n_iter = 30, n_jobs=4, cv = 5, verbose=2, random_state=1001)\n",
    "gsearch.fit(features_hot, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The MAE using optimal xgboost according to 5 fold validation is ', -gsearch.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
